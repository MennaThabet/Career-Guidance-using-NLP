{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "W6UAPtUhUjxD"
      },
      "outputs": [],
      "source": [
        "# Patch Experta for Python 3.10+ Compatibility\n",
        "import collections\n",
        "import collections.abc\n",
        "collections.Mapping = collections.abc.Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQhFjd97Ux-H",
        "outputId": "94602f1f-6164-45fe-f0e8-497b590a298c"
      },
      "outputs": [],
      "source": [
        "# Install dependencies (run only once in Colab)\n",
        "!pip install experta spacy nltk\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kYXNCDG3U2Yp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import difflib\n",
        "import string\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from experta import Fact, Rule, DefFacts, KnowledgeEngine, MATCH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUJNnL3QU5US",
        "outputId": "2b4e35a2-3790-4901-f0c5-bf67f29c2d77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NLTK Data Initialization\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIu8O4dfcyEW"
      },
      "source": [
        "# ---------- Load & Clean Data ----------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "AKUEpPV8U9B6"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/Career Guidance Expert System.csv\"\n",
        "data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pV_OsOj7cAkC"
      },
      "outputs": [],
      "source": [
        "# Replace empty lists with NaN for handling\n",
        "data.replace({\"[]\": np.nan}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "R_L3jBRxVEFE"
      },
      "outputs": [],
      "source": [
        "# Convert skill strings to actual lists\n",
        "def to_list(entry):\n",
        "    try:\n",
        "        return [item.strip().lower() for item in ast.literal_eval(entry)]\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "data[\"hard_skill\"] = data[\"hard_skill\"].apply(to_list)\n",
        "data[\"soft_skill\"] = data[\"soft_skill\"].apply(to_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EsIRWgujVHew"
      },
      "outputs": [],
      "source": [
        "# Fill missing skills with mode values for each field\n",
        "def impute_missing_skills(df):\n",
        "    hard_mode = df.groupby(\"candidate_field\")[\"hard_skill\"].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else [])\n",
        "    soft_mode = df.groupby(\"candidate_field\")[\"soft_skill\"].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else [])\n",
        "\n",
        "    def fill(row):\n",
        "        if not row[\"hard_skill\"]:\n",
        "            row[\"hard_skill\"] = hard_mode.get(row[\"candidate_field\"], [])\n",
        "        if not row[\"soft_skill\"]:\n",
        "            row[\"soft_skill\"] = soft_mode.get(row[\"candidate_field\"], [])\n",
        "        return row\n",
        "\n",
        "    return df.apply(fill, axis=1)\n",
        "\n",
        "data = impute_missing_skills(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgkfYy_TcZUx"
      },
      "source": [
        "# ---------- Knowledge Base Construction ----------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FQkU_be0VLRT"
      },
      "outputs": [],
      "source": [
        "# Build a skill map from dataset\n",
        "career_map = {\n",
        "    field: {\n",
        "        \"hard\": set(sum(group[\"hard_skill\"].tolist(), [])),\n",
        "        \"soft\": set(sum(group[\"soft_skill\"].tolist(), []))\n",
        "    }\n",
        "    for field, group in data.groupby(\"candidate_field\")\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BobaSX38VPoQ"
      },
      "outputs": [],
      "source": [
        "# Get all known skills\n",
        "known_skills = sorted(set().union(*(entry[\"hard\"] | entry[\"soft\"] for entry in career_map.values())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E89iydNUc1j4"
      },
      "source": [
        "# ---------- NLP Initialization ----------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "CySSXmN0VV0E"
      },
      "outputs": [],
      "source": [
        "# Ensure NLTK data is downloaded before use\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "nltk.download(\"wordnet\", quiet=True)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "91aDMgc7ery7"
      },
      "outputs": [],
      "source": [
        "# Define the extract_terms function\n",
        "def extract_terms(text):\n",
        "    \"\"\"Tokenizes, removes stop words, and lemmatizes the input text.\"\"\"\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [token.text for token in doc if token.text not in string.punctuation]\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return lemmatized_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x1okj_KdR6u"
      },
      "source": [
        "# ---------- Expert System using Experta ----------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "u_60Um_pVYjF"
      },
      "outputs": [],
      "source": [
        "class Profile(Fact):\n",
        "    \"\"\"User-provided skill description\"\"\"\n",
        "    pass\n",
        "\n",
        "class Advisor(KnowledgeEngine):\n",
        "\n",
        "    @DefFacts()\n",
        "    def _init_facts(self):\n",
        "        yield Fact(intent=\"analyze\")\n",
        "\n",
        "    @Rule(Fact(intent=\"analyze\"), Profile(description=MATCH.description))\n",
        "    def suggest_career(self, description):\n",
        "        tokens = extract_terms(description)\n",
        "        matched = []\n",
        "\n",
        "        for token in tokens:\n",
        "            best_match, best_score = None, 0\n",
        "            for reference in known_skills:\n",
        "                score = difflib.SequenceMatcher(None, token, reference).ratio()\n",
        "                if score > best_score:\n",
        "                    best_match, best_score = reference, score\n",
        "            if best_score >= 0.6:\n",
        "                matched.append(best_match)\n",
        "\n",
        "        ranking = {\n",
        "            field: sum(skill in skills[\"hard\"] for skill in matched) +\n",
        "                   sum(skill in skills[\"soft\"] for skill in matched)\n",
        "            for field, skills in career_map.items()\n",
        "        }\n",
        "\n",
        "        if any(ranking.values()):\n",
        "            recommendation = max(ranking, key=ranking.get)\n",
        "            print(f\"\\n‚úÖ Recommended Career Field: **{recommendation.title()}**\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è No suitable match found. Please revise your input.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtg9N0tfdcnF"
      },
      "source": [
        "# ---------- Run System ----------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl9U-RbiODqk",
        "outputId": "ed2a4ac3-ff47-4d78-ec7d-98e8677e304d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß† Describe your experience, skills, or projects:\n",
            " \"I have experience in nursing, registration,  and service. I am also good at written communication.\"\n",
            "\n",
            "‚úÖ Recommended Career Field: **Healthcare & Medical**\n"
          ]
        }
      ],
      "source": [
        "# Get user input and run the expert system\n",
        "user_input = input(\"üß† Describe your experience, skills, or projects:\\n\")\n",
        "\n",
        "if user_input.strip():\n",
        "    expert = Advisor()\n",
        "    expert.reset()\n",
        "    expert.declare(Profile(description=user_input))\n",
        "    expert.run()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Empty input. Please try again.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
